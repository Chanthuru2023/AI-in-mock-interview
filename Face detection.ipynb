{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf641c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.44.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe80a79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load pre-trained emotion recognition model\n",
    "emotion_model = pipeline('sentiment-analysis', model='j-hartmann/emotion-english-distilroberta-base')\n",
    "\n",
    "def analyze_emotion(transcription):\n",
    "    emotions = emotion_model(transcription)\n",
    "    return emotions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f06dc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5712f5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34360\\4160281558.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;31m# Call the function to start detecting face and eye contact\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m \u001b[0mdetect_face_and_eyes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34360\\4160281558.py\u001b[0m in \u001b[0;36mdetect_face_and_eyes\u001b[1;34m()\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;31m# Stop if the escape key is pressed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0xFF\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m27\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''import cv2\n",
    "\n",
    "def detect_face_and_eyes():\n",
    "    # Load the cascade classifiers for face and eye detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "    # Capture video from the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Read each frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        # Draw rectangle around the faces and detect eyes\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = gray[y:y + h, x:x + w]\n",
    "            roi_color = frame[y:y + h, x:x + w]\n",
    "\n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "            for (ex, ey, ew, eh) in eyes:\n",
    "                cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "\n",
    "        # Display the video frame\n",
    "        cv2.imshow('Face and Eye Detection', frame)\n",
    "\n",
    "        # Stop if the escape key is pressed\n",
    "        if cv2.waitKey(30) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    # Release the VideoCapture object\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Call the function to start detecting face and eye contact\n",
    "detect_face_and_eyes()'''\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "def show_popup():\n",
    "    # Create a simple popup window\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main window\n",
    "    messagebox.showwarning(\"Warning\", \"You are too far from the camera!\")\n",
    "\n",
    "def detect_face_and_eyes():\n",
    "    # Load the cascade classifiers for face and eye detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "    # Capture video from the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Read each frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        # Check if a face is detected\n",
    "        if len(faces) == 0:\n",
    "            # No face detected, skip to the next frame\n",
    "            continue\n",
    "\n",
    "        # Draw rectangle around the faces and detect eyes\n",
    "        for (x, y, w, h) in faces:\n",
    "            # If face size is smaller than a threshold, trigger a pop-up\n",
    "            if w < 100 or h < 100:  # Adjust threshold based on your testing\n",
    "                show_popup()\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = gray[y:y + h, x:x + w]\n",
    "            roi_color = frame[y:y + h, x:x + w]\n",
    "\n",
    "            # Detect eyes\n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "            for (ex, ey, ew, eh) in eyes:\n",
    "                cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "\n",
    "        # Display the video frame\n",
    "        cv2.imshow('Face and Eye Detection', frame)\n",
    "\n",
    "        # Stop if the escape key is pressed\n",
    "        if cv2.waitKey(30) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    # Release the VideoCapture object\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Call the function to start detecting face and eye contact\n",
    "detect_face_and_eyes()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e31c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/analyze', methods=['POST'])\n",
    "def analyze_interview():\n",
    "    data = request.json\n",
    "    transcription = data['transcription']\n",
    "\n",
    "    # Example NLP emotion analysis (call previously defined function)\n",
    "    emotions = analyze_emotion(transcription)\n",
    "    \n",
    "    # Sample response\n",
    "    return jsonify({\n",
    "        \"status\": \"success\",\n",
    "        \"transcription\": transcription,\n",
    "        \"emotion_analysis\": emotions\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed63b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feedback(emotion_analysis, filler_words_count, eye_contact):\n",
    "    feedback = []\n",
    "    \n",
    "    if eye_contact < 50:\n",
    "        feedback.append(\"You need to improve your eye contact during the interview.\")\n",
    "    \n",
    "    if filler_words_count > 10:\n",
    "        feedback.append(\"Try to minimize the use of filler words like 'um', 'uh', and 'like'.\")\n",
    "    \n",
    "    if any(emotion['label'] == 'sadness' for emotion in emotion_analysis):\n",
    "        feedback.append(\"Try to project more confidence in your tone.\")\n",
    "\n",
    "    return feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea2228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180fab6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6e1df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b454b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b795650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
